{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07246ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from local_models import SmallCNN, MiniResNet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import evaluate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7ede7",
   "metadata": {},
   "source": [
    "### Load and Evaluate Default Models\n",
    "\n",
    "Note that ResNet and DenseNet are both explored in previous works examining the structure of loss functions. Pretrained models are available for both through pytorch. However, these are trained in the ImageNet1K dataset which is extremely large (1.2M images). It is tbd whether I load a small portion of ImageNet1K or fine-tune both models on CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332673dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # needed for ImageNet-pretrained models\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1302b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained models\n",
    "mini_cnn = SmallCNN()\n",
    "mini_resnet = MiniResNet()\n",
    "\n",
    "mini_cnn.to(device)\n",
    "mini_resnet.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9f9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, device, num_epochs=100):\n",
    "    \"\"\" Train the models on the CIFAR10 dataset \"\"\"\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "    # Set minority of weights to be trainable (linear maps)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # Fine-tune on the training set for a given number of epochs\n",
    "    for epoch, (image, labels) in tqdm(enumerate(loader)):\n",
    "        if epoch > num_epochs: break\n",
    "        images, labels = image.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "\n",
    "        if epoch % 10 == 0 and epoch != 0:\n",
    "            print(f\"Epoch {epoch}: Loss {total_loss}\")\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba413ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dcfad4005e4cd4a1c6e3bebdef0ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss 25.139097213745117\n",
      "Epoch 20: Loss 22.388288974761963\n",
      "Epoch 30: Loss 21.888100147247314\n",
      "Epoch 40: Loss 21.26663589477539\n",
      "Epoch 50: Loss 21.004374980926514\n",
      "Epoch 60: Loss 20.92983341217041\n",
      "Epoch 70: Loss 20.80238914489746\n",
      "Epoch 80: Loss 20.85324239730835\n",
      "Epoch 90: Loss 20.848198890686035\n",
      "Epoch 100: Loss 20.522931456565857\n",
      "Epoch 110: Loss 20.42978525161743\n",
      "Epoch 120: Loss 20.727654933929443\n",
      "Epoch 130: Loss 20.437235832214355\n",
      "Epoch 140: Loss 20.62094759941101\n",
      "Epoch 150: Loss 20.524761080741882\n",
      "Epoch 160: Loss 20.43184721469879\n",
      "Epoch 170: Loss 20.329602479934692\n",
      "Epoch 180: Loss 20.123048424720764\n",
      "Epoch 190: Loss 20.05565905570984\n",
      "Epoch 200: Loss 20.329110980033875\n",
      "Epoch 210: Loss 20.355631709098816\n",
      "Epoch 220: Loss 19.933977007865906\n",
      "Epoch 230: Loss 20.16918122768402\n",
      "Epoch 240: Loss 20.375797033309937\n",
      "Epoch 250: Loss 19.726994514465332\n",
      "Epoch 260: Loss 20.051657676696777\n",
      "Epoch 270: Loss 19.936481833457947\n",
      "Epoch 280: Loss 20.089476227760315\n",
      "Epoch 290: Loss 20.18186628818512\n",
      "Epoch 300: Loss 19.921929597854614\n",
      "Epoch 310: Loss 20.22816824913025\n",
      "Epoch 320: Loss 20.466865301132202\n",
      "Epoch 330: Loss 20.45198702812195\n",
      "Epoch 340: Loss 20.049269318580627\n",
      "Epoch 350: Loss 20.045535922050476\n",
      "Epoch 360: Loss 20.303112864494324\n",
      "Epoch 370: Loss 19.95144212245941\n",
      "Epoch 380: Loss 19.827510714530945\n",
      "Epoch 390: Loss 20.128781914711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99e238c71ea44d18e5db3d334dce63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2691 0.03112415976524353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1b3df0b31848d8a57ed4c79f6586c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss 25.449487924575806\n",
      "Epoch 20: Loss 22.923524141311646\n",
      "Epoch 30: Loss 22.808921813964844\n",
      "Epoch 40: Loss 22.746204614639282\n",
      "Epoch 50: Loss 22.503289699554443\n",
      "Epoch 60: Loss 21.9004008769989\n",
      "Epoch 70: Loss 21.364984035491943\n",
      "Epoch 80: Loss 21.068109035491943\n",
      "Epoch 90: Loss 20.855353355407715\n",
      "Epoch 100: Loss 21.000168085098267\n",
      "Epoch 110: Loss 20.919428944587708\n",
      "Epoch 120: Loss 20.678924083709717\n",
      "Epoch 130: Loss 20.54681372642517\n",
      "Epoch 140: Loss 20.364158868789673\n",
      "Epoch 150: Loss 19.93267321586609\n",
      "Epoch 160: Loss 20.4872328042984\n",
      "Epoch 170: Loss 20.283712029457092\n",
      "Epoch 180: Loss 20.318406462669373\n",
      "Epoch 190: Loss 20.38431179523468\n",
      "Epoch 200: Loss 20.507373332977295\n",
      "Epoch 210: Loss 20.326703310012817\n",
      "Epoch 220: Loss 19.98502016067505\n",
      "Epoch 230: Loss 20.311936736106873\n",
      "Epoch 240: Loss 20.28835391998291\n",
      "Epoch 250: Loss 20.273168444633484\n",
      "Epoch 260: Loss 20.25411605834961\n",
      "Epoch 270: Loss 20.123975038528442\n",
      "Epoch 280: Loss 20.153377532958984\n",
      "Epoch 290: Loss 20.05859923362732\n",
      "Epoch 300: Loss 20.088075637817383\n",
      "Epoch 310: Loss 20.15795087814331\n",
      "Epoch 320: Loss 20.12723433971405\n",
      "Epoch 330: Loss 20.0316641330719\n",
      "Epoch 340: Loss 19.927385330200195\n",
      "Epoch 350: Loss 19.627122163772583\n",
      "Epoch 360: Loss 20.224157691001892\n",
      "Epoch 370: Loss 20.023440718650818\n",
      "Epoch 380: Loss 20.07102334499359\n",
      "Epoch 390: Loss 19.96800136566162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22496d5c8b94aa3ad32a725e49c1160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2691 0.031153733611106873\n"
     ]
    }
   ],
   "source": [
    "# For both models, finetune, evaluate, and save\n",
    "train(mini_cnn, trainloader, device, num_epochs=500)\n",
    "mini_cnn_acc, mini_cnn_loss = evaluate(model=mini_cnn, loader=testloader, loss_fn=loss_fn, device=device)\n",
    "print(mini_cnn_acc, mini_cnn_loss)\n",
    "torch.save(mini_cnn.state_dict(), 'models/mini_cnn_cifar10.pt')\n",
    "\n",
    "train(mini_resnet, trainloader, device, num_epochs=500)\n",
    "mini_resnet_acc, mini_resnet_loss = evaluate(model=mini_resnet, loader=testloader, loss_fn=loss_fn, device=device)\n",
    "print(mini_cnn_acc, mini_resnet_loss)\n",
    "torch.save(mini_resnet.state_dict(), 'models/mini_resnet_cifar10.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
